{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import textstat\n",
    "# nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from textblob import TextBlob\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data.csv\")\n",
    "df = df.drop('tweet_date', axis=1)\n",
    "\n",
    "dfDate=pd.read_csv('dataAppleDate.csv')\n",
    "\n",
    "df = pd.merge(df, dfDate, on='id')\n",
    "df.drop_duplicates(subset=\"id\", keep=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spaCy model for NLP processing\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def count_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [ent.text for ent in doc.ents]\n",
    "    return len(entities)\n",
    "\n",
    "def sentiment_score(text):\n",
    "    doc = nlp(text)\n",
    "    sentiment = doc.sentiment\n",
    "    return sentiment.polarity\n",
    "\n",
    "def average_word_length(text):\n",
    "    words = text.split()\n",
    "    total_word_length = 0\n",
    "    for word in words:\n",
    "        total_word_length += len(word)\n",
    "    average_word_length = total_word_length / len(words)\n",
    "    return average_word_length\n",
    "\n",
    "def readability_score(text):\n",
    "    return textstat.flesch_reading_ease(text)\n",
    "    \n",
    "def get_time_period(hour):\n",
    "    if hour >= 0 and hour < 6:\n",
    "        return \"midnight to 6 AM\"\n",
    "    elif hour >= 6 and hour < 12:\n",
    "        return \"6 AM to 12 PM\"\n",
    "    elif hour >= 12 and hour < 18:\n",
    "        return \"12 PM to 6 PM\"\n",
    "    else:\n",
    "        return \"6 PM to midnight\"\n",
    "\n",
    "# function to extract the most common word from a tweet\n",
    "def extract_common_word(tweet):\n",
    "    words = nltk.word_tokenize(tweet)\n",
    "    words = [word.lower() for word in words]\n",
    "    stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    words = [word for word in words if word.isalpha() and word not in stop_words]\n",
    "    fdist = FreqDist(words)\n",
    "    common_word = fdist.most_common(1)[0][0]\n",
    "    score = fdist.most_common(1)[0][1]\n",
    "    return common_word, score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Add a feature for text length\n",
    "df['text_length'] = df['text'].apply(len)\n",
    "df['average_word_length'] = df['text'].apply(average_word_length)\n",
    "\n",
    "# Add a feature for arousal level\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "df['arousal'] = df['text'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "# df['sentiment_score'] = df['text'].apply(sentiment_score)\n",
    "df['entities_count'] = df['text'].apply(count_entities)\n",
    "df['readability_score'] = df['text'].apply(readability_score)\n",
    "\n",
    "# Convert the \"tweet_date\" column to a datetime format\n",
    "df[\"tweet_date\"] = pd.to_datetime(df[\"tweet_date\"])\n",
    "df[\"time_period\"] = df[\"tweet_date\"].dt.hour.apply(get_time_period)\n",
    "\n",
    "df['sentiment'] = le.fit_transform(df['sentiment'])\n",
    "df['tag'] = le.fit_transform(df['tag'])\n",
    "df['tweet_date'] = le.fit_transform(df['tweet_date'])\n",
    "df['time_period'] = le.fit_transform(df['time_period'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Tweet_Metrics=df[['id','like_count','retweet_count','quote_count']]\n",
    "\n",
    "# Data that can be collected to complete the model in the future\n",
    "# df_Tweet_Metrics=df[['id','like_count','retweet_count','quote_count','reply_count','impression_count','metrics24h','metrics7day']]\n",
    "\n",
    "# df_Tweet_Text=df[['id','author_id','tag','sentiment','arousal','average_word_length','text_length','entities_count','readability_score','time_period','tweet_date','jaccard']]\n",
    "df_Tweet_Text=df[['id','sentiment','time_period','tweet_date','jaccard','average_word_length','text_length']]\n",
    "# Data that can be collected to complete the model in the future\n",
    "# df_Tweet_Text=df[['text','clean_text','sentiment','arousal','average_word_length','text_length','readability_score','time_period','tweet_date','geo','possibly_sensitive','reply_settings','context','jaccard']]\n",
    "\n",
    "df_User=df[['id','followers_count','following_count']]\n",
    "# Data that can be collected to complete the model in the future\n",
    "# df_User=df[['followers_count','following_count','metrics_24h','metrics_7day','SST','LSM','verified','location','description','sentiment_description','verified_type','tweet_count','fakeAccountRate']]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virality :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# virality_metrics = (like_count + retweet_count + quote_count) * sentiment_score\n",
    "\n",
    "# virality_evolution = delta (metrics_T0, metrics_24H, metrics7DAY)\n",
    "\n",
    "# virality_interaction = (tweet_metrics) * sentiment_score + (reply_metrics,quote_metrics) * sentiment_score \n",
    "\n",
    "# virality_global = virality_metrics + virality_evolution + virality_interaction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.merge(df_User, df_Tweet_Text, on='id')\n",
    "df2 = df2.drop('id', axis=1)\n",
    "df_Tweet_Metrics = df_Tweet_Metrics.drop('id', axis=1)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data, train_target, test_target = train_test_split(df2, df_Tweet_Metrics, test_size=0.2)\n",
    "\n",
    "# Fit a linear regression model to the training data\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(train_data, train_target)\n",
    "\n",
    "# Use the model to make predictions on the test data\n",
    "predictions = regressor.predict(test_data)\n",
    "\n",
    "# Evaluate the model's performance by comparing the predictions to the actual target values\n",
    "error = test_target - predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 2291.869359565716\n",
      "Mean Squared Error (MSE): 150629777.7915829\n",
      "Root Mean Squared Error (RMSE): 12273.132354520703\n",
      "R-Squared (R2): 0.009051736237079297\n",
      "Mean Absolute Percentage Error (MAPE): like_count              inf\n",
      "retweet_count    312.842376\n",
      "quote_count      364.695997\n",
      "dtype: float64 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\fromnumeric.py:3462: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the mean absolute error (MAE)\n",
    "# MAE measures the average magnitude of the errors in a set of predictions\n",
    "# A lower MAE indicates a better fit\n",
    "mae = mean_absolute_error(test_target, predictions)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n",
    "# Calculate the mean squared error (MSE)\n",
    "# MSE measures the average of the square of the errors, which gives more weight to larger errors\n",
    "# A lower MSE indicates a better fit\n",
    "mse = mean_squared_error(test_target, predictions)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# Calculate the root mean squared error (RMSE)\n",
    "# RMSE is the square root of the MSE, and is used to provide a more interpretable result\n",
    "# A lower RMSE indicates a better fit\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "\n",
    "# Calculate R-squared\n",
    "# R-squared measures the proportion of the variance in the target variable that is explained by the model\n",
    "# A higher R-squared value indicates a better fit\n",
    "r2 = r2_score(test_target, predictions)\n",
    "print(\"R-Squared (R2):\", r2)\n",
    "\n",
    "# Calculate the mean absolute percentage error (MAPE)\n",
    "# MAPE measures the average percentage error of the predictions\n",
    "# A lower MAPE indicates a better fit\n",
    "mape = np.mean(np.abs((test_target - predictions) / test_target)) * 100\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape, \"%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc2a200e1e6dab10c4dc3986f0e7a998296447c993c26561a1bd050a849d8214"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
