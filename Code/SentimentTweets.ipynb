{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from datetime import datetime\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "project_id = 'snsdisasteralert-372409'\n",
    "client = bigquery.Client(project=project_id)\n",
    "\n",
    "# Insert values in a table\n",
    "from google.cloud import bigquery\n",
    "# client = bigquery.Client()\n",
    "\n",
    "dataset_id = \"sns\"\n",
    "# For this sample, the table must already exist and have a defined schema\n",
    "table_id = \"tweets\"\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "table = client.get_table(table_ref)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM `snsdisasteralert-372409.sns.data3` \n"
     ]
    }
   ],
   "source": [
    "# Running this code will display the query used to generate your previous job\n",
    "\n",
    "job = client.get_job('bquxjob_2c59c7e9_185dad4c022') # Job ID inserted based on the query results selected to explore\n",
    "print(job.query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>like_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>f0_</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>tag</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>virality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1565148948263837696</td>\n",
       "      <td>809532994444591104</td>\n",
       "      <td>#Serena Williams. \\n\\nThatâ€™s it. Thatâ€™s the tw...</td>\n",
       "      <td>20</td>\n",
       "      <td>1990</td>\n",
       "      <td>211</td>\n",
       "      <td>353230</td>\n",
       "      <td>990</td>\n",
       "      <td>0.665685</td>\n",
       "      <td>2022-09-01 00:00:00+00:00</td>\n",
       "      <td>twitter</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1578859624648036352</td>\n",
       "      <td>1083283217141170176</td>\n",
       "      <td>Nicki Minaj got 14+ of her songs trending on t...</td>\n",
       "      <td>17</td>\n",
       "      <td>3030</td>\n",
       "      <td>384</td>\n",
       "      <td>9183</td>\n",
       "      <td>2978</td>\n",
       "      <td>0.472328</td>\n",
       "      <td>2022-10-08 00:00:00+00:00</td>\n",
       "      <td>twitter</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1577460057771384832</td>\n",
       "      <td>1200616796295847936</td>\n",
       "      <td>Elon's first day at Twitter? https://t.co/YRkl...</td>\n",
       "      <td>107</td>\n",
       "      <td>5668</td>\n",
       "      <td>832</td>\n",
       "      <td>1065567</td>\n",
       "      <td>2388</td>\n",
       "      <td>0.623323</td>\n",
       "      <td>2022-10-05 00:00:00+00:00</td>\n",
       "      <td>twitter</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1577093985515945984</td>\n",
       "      <td>42987732</td>\n",
       "      <td>Jamaal Williams somehow found my tweet from Sa...</td>\n",
       "      <td>3</td>\n",
       "      <td>2989</td>\n",
       "      <td>70</td>\n",
       "      <td>178068</td>\n",
       "      <td>1062</td>\n",
       "      <td>0.550796</td>\n",
       "      <td>2022-10-04 00:00:00+00:00</td>\n",
       "      <td>twitter</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1575730292756660224</td>\n",
       "      <td>906362637264478208</td>\n",
       "      <td>(trans)\\n-they called MileApo as the hottest y...</td>\n",
       "      <td>122</td>\n",
       "      <td>2750</td>\n",
       "      <td>1495</td>\n",
       "      <td>19257</td>\n",
       "      <td>258</td>\n",
       "      <td>0.485236</td>\n",
       "      <td>2022-09-30 00:00:00+00:00</td>\n",
       "      <td>twitter</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218210</th>\n",
       "      <td>1536791997176074241</td>\n",
       "      <td>237941903</td>\n",
       "      <td>AWS is now recruiting for some open roles in L...</td>\n",
       "      <td>17</td>\n",
       "      <td>1555</td>\n",
       "      <td>765</td>\n",
       "      <td>5025</td>\n",
       "      <td>481</td>\n",
       "      <td>0.595576</td>\n",
       "      <td>2022-06-14 00:00:00+00:00</td>\n",
       "      <td>amazon</td>\n",
       "      <td>positive</td>\n",
       "      <td>2337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218211</th>\n",
       "      <td>1494317805826498564</td>\n",
       "      <td>180740221</td>\n",
       "      <td>#ContestAlert\\nThe scarier the better! ðŸ˜¨ðŸ˜² The ...</td>\n",
       "      <td>12</td>\n",
       "      <td>342</td>\n",
       "      <td>268</td>\n",
       "      <td>22610</td>\n",
       "      <td>19</td>\n",
       "      <td>0.421802</td>\n",
       "      <td>2022-02-17 00:00:00+00:00</td>\n",
       "      <td>amazon</td>\n",
       "      <td>positive</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218212</th>\n",
       "      <td>1549122392986750976</td>\n",
       "      <td>3153323480</td>\n",
       "      <td>i stopped at the kettleman city supercharger &amp;...</td>\n",
       "      <td>6</td>\n",
       "      <td>911</td>\n",
       "      <td>50</td>\n",
       "      <td>21414</td>\n",
       "      <td>918</td>\n",
       "      <td>1.036286</td>\n",
       "      <td>2022-07-18 00:00:00+00:00</td>\n",
       "      <td>tesla</td>\n",
       "      <td>positive</td>\n",
       "      <td>967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218213</th>\n",
       "      <td>1477725409542348813</td>\n",
       "      <td>39568716</td>\n",
       "      <td>Watching the darts but how big is the Amazon E...</td>\n",
       "      <td>0</td>\n",
       "      <td>494</td>\n",
       "      <td>9</td>\n",
       "      <td>1183</td>\n",
       "      <td>1410</td>\n",
       "      <td>0.744462</td>\n",
       "      <td>2022-01-02 00:00:00+00:00</td>\n",
       "      <td>amazon</td>\n",
       "      <td>positive</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218214</th>\n",
       "      <td>1600342518561787904</td>\n",
       "      <td>720877806</td>\n",
       "      <td>Twitter remains the best showcase money can bu...</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>24</td>\n",
       "      <td>3892</td>\n",
       "      <td>1131</td>\n",
       "      <td>0.419155</td>\n",
       "      <td>2022-12-07 00:00:00+00:00</td>\n",
       "      <td>twitter</td>\n",
       "      <td>positive</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218215 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id            author_id  \\\n",
       "0       1565148948263837696   809532994444591104   \n",
       "1       1578859624648036352  1083283217141170176   \n",
       "2       1577460057771384832  1200616796295847936   \n",
       "3       1577093985515945984             42987732   \n",
       "4       1575730292756660224   906362637264478208   \n",
       "...                     ...                  ...   \n",
       "218210  1536791997176074241            237941903   \n",
       "218211  1494317805826498564            180740221   \n",
       "218212  1549122392986750976           3153323480   \n",
       "218213  1477725409542348813             39568716   \n",
       "218214  1600342518561787904            720877806   \n",
       "\n",
       "                                                     text  like_count  \\\n",
       "0       #Serena Williams. \\n\\nThatâ€™s it. Thatâ€™s the tw...          20   \n",
       "1       Nicki Minaj got 14+ of her songs trending on t...          17   \n",
       "2       Elon's first day at Twitter? https://t.co/YRkl...         107   \n",
       "3       Jamaal Williams somehow found my tweet from Sa...           3   \n",
       "4       (trans)\\n-they called MileApo as the hottest y...         122   \n",
       "...                                                   ...         ...   \n",
       "218210  AWS is now recruiting for some open roles in L...          17   \n",
       "218211  #ContestAlert\\nThe scarier the better! ðŸ˜¨ðŸ˜² The ...          12   \n",
       "218212  i stopped at the kettleman city supercharger &...           6   \n",
       "218213  Watching the darts but how big is the Amazon E...           0   \n",
       "218214  Twitter remains the best showcase money can bu...           2   \n",
       "\n",
       "        retweet_count  quote_count  followers_count  following_count  \\\n",
       "0                1990          211           353230              990   \n",
       "1                3030          384             9183             2978   \n",
       "2                5668          832          1065567             2388   \n",
       "3                2989           70           178068             1062   \n",
       "4                2750         1495            19257              258   \n",
       "...               ...          ...              ...              ...   \n",
       "218210           1555          765             5025              481   \n",
       "218211            342          268            22610               19   \n",
       "218212            911           50            21414              918   \n",
       "218213            494            9             1183             1410   \n",
       "218214            146           24             3892             1131   \n",
       "\n",
       "             f0_                tweet_date      tag sentiment  virality  \n",
       "0       0.665685 2022-09-01 00:00:00+00:00  twitter   neutral         0  \n",
       "1       0.472328 2022-10-08 00:00:00+00:00  twitter   neutral         0  \n",
       "2       0.623323 2022-10-05 00:00:00+00:00  twitter   neutral         0  \n",
       "3       0.550796 2022-10-04 00:00:00+00:00  twitter   neutral         0  \n",
       "4       0.485236 2022-09-30 00:00:00+00:00  twitter   neutral         0  \n",
       "...          ...                       ...      ...       ...       ...  \n",
       "218210  0.595576 2022-06-14 00:00:00+00:00   amazon  positive      2337  \n",
       "218211  0.421802 2022-02-17 00:00:00+00:00   amazon  positive       622  \n",
       "218212  1.036286 2022-07-18 00:00:00+00:00    tesla  positive       967  \n",
       "218213  0.744462 2022-01-02 00:00:00+00:00   amazon  positive       503  \n",
       "218214  0.419155 2022-12-07 00:00:00+00:00  twitter  positive       172  \n",
       "\n",
       "[218215 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running this code will read results from your previous job\n",
    "\n",
    "job = client.get_job('bquxjob_2c59c7e9_185dad4c022') # Job ID inserted based on the query results selected to explore\n",
    "results = job.to_dataframe()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thi exampl tweet smiling_face_with_open_mouth emoji , link imag url\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "\n",
    "\n",
    "# 'Emoji_Dict.p'- download link https://drive.google.com/open?id=1G1vIkkbqPBYPKHcQ8qy0G2zkoab2Qv4v\n",
    "with open('Emoji_Dict.p', 'rb') as fp:\n",
    "    Emoji_Dict = pickle.load(fp)\n",
    "Emoji_Dict = {v: k for k, v in Emoji_Dict.items()}\n",
    "\n",
    "def convert_emojis_to_word(text):\n",
    "    for emot in Emoji_Dict:\n",
    "        text = re.sub(r'('+emot+')', \"_\".join(Emoji_Dict[emot].replace(\",\",\"\").replace(\":\",\"\").split()), text)\n",
    "    return text\n",
    "\n",
    "# 'Emoticon_Dict.p'- download link https://drive.google.com/open?id=1HDpafp97gCl9xZTQWMgP2kKK_NuhENlE\n",
    "with open('Emoticon_Dict.p', 'rb') as fp:\n",
    "    Emoticon_Dict = pickle.load(fp)\n",
    "\n",
    "def remove_emoticons(text):\n",
    "    emoticon_pattern = re.compile(u'(' + u'|'.join(k for k in Emoticon_Dict) + u')')\n",
    "    return emoticon_pattern.sub(r'', text)\n",
    "    \n",
    "\n",
    "# Initialize objects\n",
    "ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess(text):\n",
    "    text=convert_emojis_to_word(text)\n",
    "    text=remove_emoticons(text)\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    # Perform stemming or lemmatization\n",
    "    tokens = [ps.stem(token) for token in tokens]\n",
    "    # Identify and process Emoji\n",
    "    tokens = [token for token in tokens if not re.search(':[a-z_]+:', token)]\n",
    "    # Identify and process URLs and image links\n",
    "    tokens = [token for token in tokens if re.sub(r'http\\S+', '', token)]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Example usage\n",
    "text = \"This is an example tweet with a ðŸ˜ƒ emoji, a link to an image https://example.com/image.jpg and a URL http://www.example.com\"\n",
    "print(preprocess(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from afinn import Afinn\n",
    "\n",
    "# Load your dataset of tweets into a Pandas dataframe\n",
    "tweets_df = results\n",
    "\n",
    "# Create a VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "afinn=Afinn()\n",
    "\n",
    "# Define a function to perform sentiment analysis on a single tweet\n",
    "def analyze_sentiment(tweet):\n",
    "    # tweet = preprocess(tweet)\n",
    "    # Get the sentiment scores for the tweet text\n",
    "    sentiment_scores = analyzer.polarity_scores(tweet)\n",
    "    # Extract the compound sentiment score\n",
    "    compound_score = sentiment_scores['compound']\n",
    "    # Map the compound score to a sentiment label (positive, neutral, negative)\n",
    "    if compound_score >= 0.05:\n",
    "        sentiment_label = 'positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        sentiment_label = 'negative'\n",
    "    else:\n",
    "        sentiment_label = 'neutral'\n",
    "    return sentiment_label\n",
    "# Define a function to perform sentiment analysis on a single tweet\n",
    "def analyze_sentiment2(tweet):\n",
    "    # tweet = preprocess(tweet)\n",
    "    # Get the sentiment scores for the tweet text\n",
    "    sentiment_scores = afinn.score(tweet)\n",
    "    # Extract the compound sentiment score\n",
    "    # compound_score = sentiment_scores['compound']\n",
    "    # Map the compound score to a sentiment label (positive, neutral, negative)\n",
    "    if sentiment_scores >  0:\n",
    "        sentiment_label = 'positive'\n",
    "    elif sentiment_scores < 0:\n",
    "        sentiment_label = 'negative'\n",
    "    else:\n",
    "        sentiment_label = 'neutral'\n",
    "    return sentiment_label\n",
    "\n",
    "# Apply the sentiment analysis function to each tweet in the dataset\n",
    "tweets_df['text_clean'] = tweets_df['text'].apply(preprocess)\n",
    "tweets_df['sentiments'] = tweets_df['text_clean'].apply(analyze_sentiment)\n",
    "tweets_df['sentimentss'] = tweets_df['text_clean'].apply(analyze_sentiment2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of similarity between sentiment and sentiments is 80.61%\n",
      "The percentage of similarity between sentiment and sentiments_2 is 73.84%\n",
      "The percentage of similarity between sentiments and sentiments_2 is 85.74%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset into a Pandas dataframe\n",
    "df =tweets_df\n",
    "\n",
    "# Compare the sentiment labels in the three columns\n",
    "comparison_1 = df['sentiment'] == df['sentiments']\n",
    "comparison_2 = df['sentiment'] == df['sentimentss']\n",
    "comparison_3 = df['sentiments'] == df['sentimentss']\n",
    "\n",
    "# Calculate the percentage of similarity\n",
    "similarity_1 = comparison_1.mean() * 100\n",
    "similarity_2 = comparison_2.mean() * 100\n",
    "similarity_3 = comparison_3.mean() * 100\n",
    "\n",
    "print(f\"The percentage of similarity between sentiment and sentiments is {similarity_1:.2f}%\")\n",
    "print(f\"The percentage of similarity between sentiment and sentiments_2 is {similarity_2:.2f}%\")\n",
    "print(f\"The percentage of similarity between sentiments and sentiments_2 is {similarity_3:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.to_csv('datasent.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv('azeaezf.csv')\n",
    "newdf = tweets_df.drop(['sentiment', 'sentiments', 'Unnamed: 0'], axis=1)\n",
    "newdf = newdf.rename(columns={'sentimentss': 'sentiment'})\n",
    "newdf = newdf.rename(columns={'f0_': 'jaccard'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas_gbq\n",
    "project_id = 'snsdisasteralert-372409'\n",
    "table_id='sns.data4'\n",
    "pandas_gbq.to_gbq(newdf, table_id, project_id=project_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc2a200e1e6dab10c4dc3986f0e7a998296447c993c26561a1bd050a849d8214"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
